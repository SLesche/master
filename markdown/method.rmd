# Algorithm
## Implementation in Matlab with details
We implemented the algorithm in MATLAB [VERSION, CITATION]. Data must be in ERPLAB - shape **better way**. The researcher then specifies the name and polarity of the component of interest as well as the measurement window. This window is used to extract the template. In order to transform the template, we use MATLABs Curve Fitting Toolbox [Citation] to generate _sum of sines_ functions that fit to the data with $R^2 \ge 0.999$. We then add an amplitude parameter $a$ to the overall function in order to allow for scaling of the amplitude of the template and a frequency parameter $b$ to all frequency terms in the _sum of sines_ function to allow for "squishing" or "stretching" the template along the x-Axis. The template is described by a function $f(x, a, b)$ with $n$ sine terms and their respective amplitude $A_i$, frequency $f_i$ and phase $\phi_i$. 

$$f(x, a,b ) = \sum_{i = 1}^{n} a*(A_isin(b*f_ix + \phi_i)$$
As these transformations also change the measurement window, we chose to use the subject-level ERP as a template and keep the grand average untransformed as a signal. This reverse matching approach is only an implementation detail and does not affect any decisions made by the algorithm.

Depending on the similarity measure employed, we use different functions to find the set of optimal parameters $[a_j, b_j]$ that lead to the transformation of ERP of subject $j$ most similar to the grand average. 

### MINSQ
The MINSQ algorithm minimizes the weighted sum $S$ of squared differences $d$ between the transformed subject signal and the grand average. 
$$S = \sum_{i = 1}^{n}\omega_{i}d_{i}^2$$
This weighting vector $\omega$ is computed as follows
$$\omega_i = 1+\mathbb{1}_{[t_{start}, t_{end}]}(x_i)(10 * |\frac{y_i}{y_{max}}|)^2$$
Where 
$$\mathbb{1}_{[t_{start}, t_{end}]}(x_i) = \begin{cases} 1 & \text{if $t_{start} \le x_i \le t_{end}$} \\ 0 & \text{otherwise}\end{cases}$$$[t_{start}, t_{end}]$ denotes the measurement window, $y_{i}$ the signal strength of the $i$th element, $y_{max}$ the maximum voltage deflection inside the measurement window and $x_i$ the time of the $i$th element.

This places more emphasis on fitting the template within the measurement window specified and to places in the signal where the voltage deflection is high. 

We use MATLABs _fit_ function to find optimal parameters $[a_j, b_j]$ with upper and lower bounds such that $a_j \in [0, 50]; b_j \in [0.5, 3]$. As this function may be prone to converging on local minima, we initialize 5 different start points. The solution with the best correlation between transformed template and signal that multiple start points converged on is selected.

In cases where the subject-level ERP only has signal with deflections opposite of the deflection of the component of interest, it may occur that the parameter $a_j \le 0$. In these cases, we attempt to re-match the signal with an added parameter $d$ shifting the entire template up or down. 
$$f(x, a,b, d) = d +\sum_{i = 1}^{n} a*(A_isin(b*f_ix + \phi_i)$$ 
Should the algorithm again converge on a solution with $a_j \le 0$, the latency value is set to NA.

### CORR
The CORR algorithm optimizes the parameters to produce the maximal correlation $r_{st}$ between the transformed subject-level signal $s$ and the grand average $t$ for values in the measurement window. 
$$r_{st} = \frac{\sum(s_i - \bar{s})(t_{i} - \bar{t})}{\sqrt{\sum(s_i - \bar{s})^2(t_{i} - \bar{t})^2}}$$
$t$ represents the vector of values of the transformed subject ERP that are in the measurement window, $s$ the vector of values of the grand average that are in the measurement window. 

MATLABs _fminbnd_ function finds the optimal transformation parameter $b_j$ maximizing $r_{st}$. This function will estimate the objective function for all values inside the given bounds $b_j \in [0.5, 2]$ and converge on the global optimum. We do not need to initialize a number of different starting points here.

Both algorithms then return the transformation parameters $[a_j, b_j]$ that result in optimal similarity of transformed template and signal. We use the returned value of the parameter $b_j$ to transform the component latency specified by the researcher in the grand average $l_{GA}$ to the component latency of the subject-level ERP signal $l_j$. 
$$ l_j = l_{GA} * b_j $$

## Review methods
Researchers can manually review all choices the algorithm has made in a custom-built user interface. For both algorithms, we used the correlation between transformed template and signal as a fit-index. This can be used to only review those cases where the correlation between template and signal dips below a certain value, indicating low similarity between matched template and signal. We will investigate the additional benefits a manual review process provides over accepting the choices as-is or only automatically discarding those matches with correlations $r_{st} \le .20$.

# Data
The data used here were first published by [Sadus 2023] and are a subset of the data collected by [Löffler REF].

## Participants
The data is comprised of 30 young participants (18-21 years old, mean age = 19.37, SD age = 0.76) and 30 old participants (50-60 years old, mean age = 55.83, SD age = 2.87). This sample was part of a larger study [Löffler REF] of which the 30 youngest and 30 oldest participants were selected. All participants had normal or corrected to normal vision. None of the participants had neurological or mental disorders, used psychotropic drugs, wore a pacemaker or suffered from red-green color vision deficiency. The participants provided informed consent prior to participation and received 75€ or course credit for participation. **ethics stuff?**

## Tasks
Participants completed a set of 3 tasks: a Flanker Task, an Nback Task and a Switching Task. These tasks each measure one of the executive functions proposed by [Miyake, 2000]. [Löffler] programmed all tasks in MATLAB [ref] using the software package Psychtoolbox [version 3-0.13, REF]. Stimuli were presented centrally on a black background. We instructed participants to respond as quickly and accurately as possible. 

### Flanker Task
We administered a standard Arrow Flanker task [Eriksen & Eriksen 1974] to measure participants' _inhibition_ ability. A central arrow pointing either to the left or to the right is flanked by two additional arrows to each side. These flanking arrows either point in the same or in the opposite direction as the central arrow. Participants have to respond by button press in which direction the central arrow pointed, disregarding the congruent or incongruent flanking arrows. Participants completed a set of practice trials and a total of 100 congruent and 100 incongruent trials.

### Nback Task
We administered an adapted version of the Nback task from [Scharinger 2015] to measure participants' _updating_ abilities. A stream of letters is shown to the participant. In the 0-back condition, participants have to indicate by keypress whether the presented letter is equivalent to a target letter. In the 1-back condition, participants have to indicate whether the currently presented letter is the same as the letter presented one trial before or not. [Löffler] also had participants complete a 2-back condition. We excluded this condition from our analysis as it did not produce clear ERPs. Participants completed a set of practice trials and a total of 96 trials per condition.

### Switching Task
We administered a Switching task to measure participants' _shifting_ ability. A stream of colored digits ranging from 1 to 9 was presented. Participants had to indicate whether the digit was greater than or less than 5 or whether the digit was odd or even depending on the color of the stimulus. A colored fixation cross just prior to stimulus presentation cued the rule participants had to follow in the upcoming trial. Participants had to either follow the same rule as in the trial before or switch to the other rule. Participants completed a set of practice trials and 192 trials each in the repeat and in the switch condition.

## Procedure
The original study [Löffler] consisted of three test sessions. The three tasks this study focuses on were all administered in the first session. The second session also included EEG measurement with 3 additional tasks. The third session was used to measure intelligence and working memory capacity. No EEG measurements were taken here. In sessions including EEG measurements, participants were seated approximately 140cm away from a monitor in a sound-attenuated room.

## EEG recording and processing
EEG was recorded using 32 Ag/AgCl scalp electrodes placed in the 10-20 system. Additional electrooculogram (EOG) measures were taken by two electrode placed above and below the left eye to correct for ocular artifacts. All impedances were kept below 5 kΩ. The signal was recorded with a sampling rate of 1000 Hz (band-pass 0.1 Hz - 100 Hz) and online-referenced to Cz. Following data acquisition, the raw data was down-sampled to 250 Hz. To remove artifacts we conducted an ICA on a cloned version of the dataset down-sampled to 100 Hz and passed through an additional high-pass filter of 1 Hz. Both the original down-sampled data as well as the ICA-dataset were cleaned by removing channels with unusually long flatlines, artifact-rates or line-noise. Channels removed were interpolated following this procedure and the data was re-referenced to the average across electrodes. ICA was conducted using the InfoMax algorithm and the resulting decomposition applied to the original dataset. ICs were labelled using the ICLabel Algorithm [Pio-Tonachini et al. 2019, aus sadus] and removed if the IC was less than 50% likely to be brain activity.  We then applied Butterworth low-pass filters with varying cutoff frequencies (8 Hz, 16 Hz, 32 Hz) and a roll-off of 12 dB/octave. Data was segmented into 1200ms long segments starting 200ms before stimulus onset. Segments containing artifacts were automatically detected and removed. As a last step, we conducted a baseline correction using the 200ms prior to stimulus onset.

## ERP analysis
Analyses were conducted in MATLAB [Version, citation]. We only included correct trials into analysis. We investigated the ERPs containing the P3b at the electrode Pz, similar to previous literature [REFS].

### Latency extraction
To evaluate the impact of the specified measurement window, we extracted latencies three separate times using either a narrow (250-600ms), medium (200-700ms) or wide (150-900ms) measurement window. We used the peak latency approach to determine the latency of the P3 in the grand averages. We applied our algorithms using both the distance-based (MINSQ) and correlation-based (CORR) similarity measures to the data and obtained transformation parameters and fit values. Subject-level latencies were recovered from the respective grand average latency and the subject-specific transformation parameters.
We also ran a traditional simple peak latency algorithm and a fractional area latency algorithm determining the 50% area latency. This was either done in an uninformed fashion, using the measurement window specified beforehand or with an adapted measurement window, based on the transformation parameters returned by the template matching algorithms. If the CORR algorithm returns the parameter $b_j = 1.1$ for participant $j$, for example, the medium measurement window of this participant would be transformed from 200-700ms to 245-745ms.
To investigate the benefits of manually reviewing the decisions of the algorithm, we chose to review all matches that resulted in fit values $r_{st} \le .60$. We then inspected the subject-level ERP with the matched template displayed over it and either accepted, rejected or manually determined the P3 latency of these ERPs.
We also explored the impact of automatically excluding all those matches with fit values $r_{st} \le .20$.

In our dataset, each of the 60 participants contributed 6 ERPs per task to the data. One ERP averaged over all trials of each of the two conditions and two more ERPs generated from an odd-even split on a trial level of that condition. These 360 ERPs each from the 3 different tasks were passed through 3 different low-pass filters and subjected to analyses with 3 separate measurement windows. We applied both the correlation-based (CORR) and distance-based (MINSQ) algorithm and either reviewed the results manually, discarded bad matches automatically or accepted the results regardless of fit. We also applied both a peak latency and area latency algorithm with either uninformed measurement windows or measurement windows transformed by the transformation parameters recovered from the CORR or MINSQ algorithm. This results in 3 tasks $\times$ 3 filters $\times$ 3 windows $\times$ 12 algorithms = 324 different extraction pipelines.

# Validation Techniques
We investigated the impact of latency extraction method on several psychometric properties as well as the effect size of the age effect. We also compared the methods in their correlation with manually extracted latencies, which can be seen as a benchmark for proper latency extraction [Sadus].

## Reliability
We estimated reliability $r_{tt}$ by computing Spearman-Brown corrected split-half correlations of ERPs generated from an odd-even split at the trial level. 

## Homogeneity
To compute a methods homogeneity $r_h$, we calculated its correlation with all other methods and took the mean of the Fisher-Z transformed correlation coefficients. Correlation coefficients of 1 cannot be transformed. Thus, we set all correlations $r = 1.00$ to $r = .99$. This mean correlation with other methods indicates the extent to which a particular method reflects the total of all other measures.

## Effect size?
To investigate the effect of age on P3 latencies, we ran a repeated measures ANOVA with the between factor age (young vs. old) and the within factor task (Flanker, Nback, Switching). 

## Correlation with manual extraction
To quantify the extent to which an extraction method is able to replicate the benchmark of manual extraction, we correlated the latencies extracted by a particular method with those extracted by an expert researcher in the same task and filter condition

## Impact of Filters / Measurement Window
We also quantified the impact preprocessing steps and the choice of measurement window have on the reliability and validity of extraction methods. We ran a repeated measures ANOVA with the dependent variable being either the estimated reliability of a method or its correlation with manually extracted data and the between factor filter (8 Hz vs. 16 Hz vs. 32 Hz) and the within factor measurement window (narrow vs. medium vs. wide). 


