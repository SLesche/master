# Discussion
## What we found
Our newly proposed pattern matching algorithms displayed consistently good psychometric properties and showed an improved ability to replicate human extraction behavior over previously established approaches like peak latency or area latency algorithms. Manual extraction has so far proven superior to algorithmic approaches [@sadus2023multiverse] but presents a time- and resource-intensive process. MINSQ-based algorithms were able to replicate this benchmark almost perfectly while presenting a more objective and efficient approach to latency extraction. The algorithm based on minimizing the weighted squared distance between transformed template and signal (MINSQ) correlated to [RESULT] with manually extracted ERP latencies across tasks and preprocessing steps.  Our algorithms were also more robust to the impact of different low-pass filters and measurement windows. Application of our algorithm would increase both replicability and scalability as well as significantly reduce the time and resources researchers need to spend on latency extraction.

### Reliability
A key comparison to evaluate the effectiveness of our algorithm was to test if it is better than already established, simpler algorithms. In our data, especially area latency measures showed to have consistently acceptable reliability and validity while peak area measures almost always proved worse than area latency measures. 

Regarding the reliability of extracted latencies across tasks and preprocessing steps, our algorithms did not prove superior to the area latency approach ([RESULT]). Both the MINSQ ([RESULT]) and CORR ([RESULT]) approaches had lower Spearman-Brown corrected split-half correlations. However, the differences in reliability are quite small and only carry low practical differences. This becomes even less relevant if the researcher uses latent-variable approaches to ERP latency as measurement error is controlled for by the common latent variable [REF].

### Homogeneity
Latency values extracted by the MINSQ algorithm proved to have the highest average correlation with all other extraction methods [RESULT] across tasks and preprocessing steps. A homogeneity of [RESULT] would be considered [excellent?]  [REF]. This indicates that this approach best reflects the total of all other measures. The CORR algorithm also proved superior to previously established extraction methods.
### Validity
@sadus2023multiverse showed that manually extracting latency values is the best approach to ensure good psychometric properties and high power. The ability of an algorithm to extract latency values correlating highly with those extracted by an expert ERP-researcher was therefore of high importance to us. 
Again, our algorithms proved to have a superior ability to replicate human behavior. The MINSQ algorithm had a mean correlation of [RESULT] with manually extracted latencies across tasks and preprocessing steps. Considering the reliabilites of the two algorithms, $r_{minsq} =$ [RESULT] and $r_{manual} =$ [RESULT], this correlation exceeds the theoretically maximal correlation between their true-score values $r_{max} = \sqrt{r_{minsq} \cdot r_{manual}}$ [REF]. This indicates that some amount of their measurement error covaries. We suspect that this is due to the high conceptual similarity between template matching and manual extraction. Errors in the generation of the template or related to the matching may be similar for human researchers and the algorithm. 

The CORR algorithm also outperformed previously established approaches in the ability to replicate human behavior, correlating very highly with manually extracted latencies ([RESULT]). Area latency measures also correlate highly with manually extracted data ([RESULT], [RESULT] for peak latency measures) but failed to match the performance of our new algorithms.

### Robustness of method
Ideally, the quality of an algorithm extracting ERP latencies is largely independent of choices made by the researcher during preprocessing. To evaluate this, we conducted ANOVAs with either the split-half correlation as an estimate for reliability or the correlation of a particular method with manually extracted latencies as an estimate of validity as the dependent variable. The filter setting (8 Hz vs. 16 Hz vs. 32 Hz) and the measurement window (narrow vs. medium vs. wide) were entered as independent variables. The filter setting used did not have an impact on any of the two measures for any algorithm. The measurement window did have an impact on the reliability of the CORR algorithm [EFFECT], area latency [EFFECT] and peak latency [EFFECT]. It also impacted the correlation with manually extracted latency for the CORR algorithm [EFFECT], MINSQ algorithm [EFFECT], area latency [EFFECT] and peak latency [EFFECT]. Our new algorithms proved to be more robust to influences of the measurement window. This is likely due to the lower conceptual influence of the measurement window in our algorithms. While the measurement window directly impacts the values of each subject-level ERP entered into analysis in prior algorithms, it only determines the template used in our algorithms. 

### Objectivity 
Any algorithmic approach to ERP latency extraction will be more objective than manually extracting ERP latencies. So we cannot crown any particular algorithm as more or less objective. The completely autonomous versions of peak latency, area latency or our algorithm with automatic rejection of bad fits are all equally objective. One strength of our approach is the ability for the researcher to inspect a subset of the ERPs based on the fit statistic of the matching procedure. This does introduce some subjectivity into the data.

### Efficiency
However, this ability of our algorithms to generate a fit statistic indicating the degree of certainty with which the match was made, is a great strength of our new algorithm. Depending on the size of their data and the degree to which researchers want to manually inspect their data, one may choose any cutoff value for the fit statistic and inspect none, a subset or all of the ERPs and the choices made by the algorithm by hand. This feature is not present in any of the previous algorithms.

## Differences MINSQ - CORR
We chose to test out two different approaches to quantifying the degree of similarity between template and signal. One minimizing the weighted squared difference and one maximizing the correlation between the two. Both showed improvements over previous algorithms and we can recommend that both approaches be studied further. We did observe some differences between the two approaches in both procedural factors as well as outcome measures.

### Procedurally
Procedurally, the largest difference between the two approaches is the optimization algorithm underlying them. Due to the invariance of the correlation of two vectors to scaling in amplitude of one vector, we can reduce the number of free parameters optimized during the CORR approach to one. This allows us to use a more exhaustive optimization algorithm that will find the global optimum in some bounded parameter space without the possibility of converging on some local optimum. This is not the case for the multivariate optimization function needed for the MINSQ approach. Here, we initialize the optimization process at several different starting points and check for convergence on a common solution indicating that this solution represents the true global optimum. This is not ideal and could be improved in the future by implementing a more suitable optimization algorithm or even improving on the one currently used.

The MINSQ algorithm may also converge on solutions where $a_j \le 0$ if the subject level signal is largely of a polarity opposite to that of the component of interest [See Figure?]. Although we did extend the variability of the template by a parameter vertically shifting the template to account for these cases, sometimes even the extended version will converge on solutions with non-sensible parameter values. This leads to missing values and unreliable fit statistics in the respective cases. In our data, this happened for [RESULT, (about 7%)] of ERP signals. A large portion of these cases may be considered _unindentifiable_ even by an expert researcher due to particularly low signal-to-noise ratios. However, some cases where the component can be identified by a human researcher or the CORR algorithm may be classified as missing by the MINSQ algorithm. We will try to implement some additional measures aiming to reduce the number of cases where the MINSQ algorithm fails to converge on a valid solution in future work.

This leads to the difference in the number of cases classified as missing by the MINSQ and CORR algorithms. While [RESULT] of cases were set to NA after manual inspection of the CORR algorithm ([RESULT] after automatic inspection), [RESULT] of cases were set to NA in the MINSQ algorithm following inspection ([RESULT] after automatic inspection). This tradeoff between better properties of the MINSQ algorithm accompanied by more missing values must be taken into account when selecting which algorithm to use. Depending on the number of participants available and the means of analysis missing values may be detrimental, leading to the CORR algorithm being the preferable choice.

The weighting vector used in the MINSQ algorithm represents another difference between the two algorithms. We used it to reflect the increased emphasis a human researcher places on those parts of the signal with the highest amplitude. The particular shape of the weighting function is somewhat arbitrary. However, its general aspects were chosen to impart some human behavior onto the algorithm. For example, the maximum-normalization conducted before weights are calculated ensures that the weighting function is scale-invariant. Furthermore, we added larger weights to values inside the measurement window without completely discarding the impact of values outside the measurement window. We also chose to square the normalized amplitude in order to reflect a non-linear relationship between amplitude and importance. The exact shape of this weighting function may be argued and optimized further.

### Results
Regarding outcome measures, the MINSQ algorithm dominates the CORR algorithm in almost all indices inspected. It has better reliability, homogeneity, validity and is more robust to the impact of measurement windows. This provides evidence towards the argument that the MINSQ algorithm presents the better choice if one is limited to the application of just one algorithm. [Something about correlational methods having problems?, brunelli2009template talks about broad peaks in multiclass pattern recognition]

## Limitations
We chose not to implement a parameter shifting the entire template along the x-axis. Thus, in our algorithm the only way latency can be shifted is by also scaling the entire component. Later peaks thus necessitate broader components. This could be changed by introducing a parameter shifting the template without scaling it. However, this would also move the amplitude at 0 ms to some other timepoint. As the origin is of special importance in ERP research, we decided against this shifting parameter. It is the only fixpoint resulting from the averaging and baselining procedures. Thus, we chose not to disturb this property. Future work may investigate the impact the introduction of this additional parameter in template transformations has on the template matching algorithm. We also limited the algorithm to linear transformations of the template but could easily extend it to include non-linear scaling as well. Non-linear scaling would enable the template transformations to capture the effect of some participants not displaying speed differences in early components (low scaling here), but showing slow late components (higher scaling here). 

During manual inspection of the choice made by the algorithms, we observed that they struggle especially with classifying subject-level ERPs containing two distinct peaks [See figure]. Both algorithms will return a match that may even fit quite well, but minor differences in the size of the two peaks can lead to inconsistencies across conditions with the algorithm choosing the first peak in one and the second peak in the other condition. Other algorithms face the same challenge. Human researchers can inspect all different ERPs belonging to the same subject and introduce some stability into the extraction method. Algorithms don't typically allow for the use of information of a previous ERP in the extraction procedure of the current ERP. During manual inspection of the choices of our algorithm, this can of course be compensated for by the human researcher.

### The present study
The generalizability of our findings is limited by the data we analyzed here. We inspected a limited sample of participants, range of tasks and number of components inspected. Depending on the component of interest, the effectiveness of different algorithms can vary [@kiesel2008measurement]. We suspect that the effectiveness of all algorithms will decline when attempting to extract earlier components. The P3 is a broad, high-amplitude and isolated component. This renders it ideal for algorithmic approaches, as the influence of surrounding components is comparatively low and the measurement window quite easily specified. Especially area latency approaches should diminish in quality due to the less isolated component structure of earlier components [@luck2014introduction]. 

## Future research
Future research should focus on applying template matching algorithms to earlier components. We also suggest simulating data to be able to quantify the algorithms ability to recover the true latency of a component. This work serves largely as a proof-of-concept. The algorithms presented here have yet to prove themselves in a larger variety of tasks, samples and for different ERP components.

We also suggest improving the optimization processes used during our algorithms. The function used to implement the optimization of the MINSQ does not consistently converge on the global optimum, which we compensated for by initializing five different starting points and testing the solutions for convergence. This could be improved upon further. 

Currently, the algorithms aim to identify this global optimum representing the absolute best similarity between transformed template and signal. It may be advantageous to rather use a linear combination of the best percentile of transformations as the solution of the optimization process. @brunelli2009template raised this issue in the context of multiclass pattern recognition. Correlation filters tend to result in broad peaks of optimality.  We currently just choose the absolute peak and the algorithm returns the corresponding transformation parameters. Choosing the highest point in that peak is influenced by noise in the same manner as peak latency algorithms. Future research should investigate using a linear transformation, like a weighted average, to make use of, for example, the top 0.1% of optimal transformations.

Aside from improvements in the implementation of the algorithm and extensions of the algorithms to earlier components, we will also improve the user interface employed for manual inspection of the choices the algorithms made. Currently, that interface displays the matched template and informs the researcher about the latency and fit statistic this match would result in. We also display the choices a peak latency and an area latency algorithm would have made. The researcher can then either accept the matched result, choose a result of the older algorithms, manually specify the component latency or reject the ERP overall due to poor identifiability. We will aim to improve this by adding a slider controlling the transformation parameters, allowing the researcher to manually match the template to the subject-level ERP. The functionality of manual latency specification will also be improved by integrating already existing software like the Measurement Tool provided by ERPLab [REF].
# Conclusion
This work provides proof-of-concept showing that template matching algorithms using the grand average as a template can be feasibly used to extract P3 latencies. Latencies extracted by our algorithm correlate highly with values extracted by an expert human researcher across tasks and preprocessing steps. Our algorithm is superior to previous algorithms like peak latency and area latency regarding the correlation with manually extracted latencies, homogeneity and robustness to the influence of different measurement windows. Our algorithms shows slightly worse reliability estimates compared to area latency approaches. A main benefit of our approach is the ability to quantify the algorithm's confidence in a particular solution via a fit statistic. This allows researchers to inspect only the subset of ERPs with the worst fits and thus correct potential measurement error of the algorithm in a time-efficient manner. Overall, the MINSQ algorithm displays better qualities than the CORR algorithm but also results in a higher number of missing values. We will aim to improve the implementation of our algorithms and test their ability to extract earlier ERP components. Overall, the results obtained here leave us optimistic regarding the applicability of this template matching approach. It will likely provide a more objective and efficient way to extract ERP latencies without greatly compromising psychometric quality.
